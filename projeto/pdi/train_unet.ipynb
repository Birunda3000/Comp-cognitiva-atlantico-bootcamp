{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 13:51:27.082803: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/erick/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-06-12 13:51:27.082834: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import utils as ut\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, Activation, SeparableConv2D, BatchNormalization, UpSampling2D\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "\n",
    "from keras.layers import concatenate as concatenate\n",
    "#from keras.layers.merge import concatenate\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import time\n",
    "inicio = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR1 = '../../../_DATA_/_DATA/ORIGINAL_GOLD/Original'\n",
    "DATADIR2 = '../../../_DATA_/_DATA/ORIGINAL_GOLD/GOLD'\n",
    "TESTDIR = '../../../_DATA_/_DATA/ORIGINAL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [00:03<00:00, 11.94it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 115.62it/s]\n",
      "100%|██████████| 66/66 [00:01<00:00, 35.64it/s]\n"
     ]
    }
   ],
   "source": [
    "proportion = 1.77777777778 # 16:9\n",
    "k = 33.75#k*32 menor dimensão da imagem (arrendondada)\n",
    "IMG_CHANNELS = 3\n",
    "EPOCHS = 150\n",
    "batch_size = 5\n",
    "save_model = True\n",
    "patience = 20#no improvement patience\n",
    "\n",
    "height = int(np.around((k * proportion), decimals=0).astype('int') * 32) # too low can cause dimension error and must be divisible by 32\n",
    "width = int(k * 32)# too low can cause dimension error and must be divisible by 32\n",
    "IMG_WIDTH_HEIGHT = max(height, width)\n",
    "\n",
    "original,_ = ut.read_imgs(path=DATADIR1, height=height, width=width, resize = True, mode = 'RGB', squared = True, square_color=(255,255,255), show = False, write=False, write_path='original')\n",
    "\n",
    "gold_masks,_ = ut.read_imgs(path=DATADIR2, height=height, width=width, resize = True, mode = 'GRAYSCALE', squared = True, square_color=(0,0,0), show = False, write=False, write_path='gold_masks')\n",
    "\n",
    "test,_ = ut.read_imgs(path=TESTDIR, height=height, width=width, resize = True, mode = 'RGB', squared = True, square_color=(255,255,255), show = False, write=False, write_path='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "for image, mask in ut.concatenate2_2_it(original, gold_masks):\n",
    "\n",
    "        X_train.append(image.astype('float32') / 255.0)\n",
    "        #plt.imshow(X_train[-1], cmap='gray')\n",
    "        #plt.show()\n",
    "        \n",
    "        aux = mask.astype('float32') / 255.0    \n",
    "        Y_train.append( np.around(aux, decimals=0).astype('uint8') )\n",
    "        #plt.imshow(Y_train[-1], cmap='gray')\n",
    "        #plt.show()\n",
    "\n",
    "for test_img in test:\n",
    "\n",
    "        X_test.append(test_img.astype('float32') / 255.0)\n",
    "        #plt.imshow(X_test[-1], cmap='gray')\n",
    "        #plt.show()\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "    \n",
    "    conv = Conv2D(n_filters, \n",
    "                  kernel_size = 3,     \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(inputs)\n",
    "    conv = Conv2D(n_filters, \n",
    "                  kernel_size = 3, \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "   \n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "        \n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(pool_size=(2,2))(conv)\n",
    "  \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    #conv = BatchNormalization()(conv)\n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,  \n",
    "                 kernel_size = 3,\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(expansive_input)\n",
    "\n",
    "    merge = concatenate([up, contractive_input], axis=3)# ??????????????????????????---------------\n",
    "\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 kernel_size = 3,   \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(merge)\n",
    "    conv = Conv2D(n_filters,  \n",
    "                 kernel_size = 3,  \n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer=tf.keras.initializers.HeNormal())(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(IMG_WIDTH_HEIGHT, IMG_WIDTH_HEIGHT\n",
    "                           , IMG_CHANNELS), n_filters=32, n_classes=3):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    #contracting path\n",
    "    cblock1 = convolutional_block(inputs, n_filters)\n",
    "    cblock2 = convolutional_block(cblock1[0], 2*n_filters)\n",
    "    cblock3 = convolutional_block(cblock2[0], 4*n_filters)\n",
    "    cblock4 = convolutional_block(cblock3[0], 8*n_filters, dropout_prob=0.2) \n",
    "    cblock5 = convolutional_block(cblock4[0],16*n_filters, dropout_prob=0.2, max_pooling=None)     \n",
    "    \n",
    "    #expanding path\n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8 * n_filters)\n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  n_filters*4)\n",
    "    ublock8 = upsampling_block(ublock7,cblock2[1] , n_filters*2)\n",
    "    ublock9 = upsampling_block(ublock8,cblock1[1],  n_filters)\n",
    "    conv9 = Conv2D(n_classes,\n",
    "                 1,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "    \n",
    "    #conv10 = Conv2D(n_classes, kernel_size=1, padding='same', activation = 'softmax')(conv9) \n",
    "    conv10 = Activation('softmax')(conv9)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 13:51:40.268065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/erick/.local/lib/python3.8/site-packages/cv2/../../lib64:\n",
      "2022-06-12 13:51:40.268105: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-12 13:51:40.268142: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lasid30): /proc/driver/nvidia/version does not exist\n",
      "2022-06-12 13:51:40.268444: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "8/8 [==============================] - 758s 92s/step - loss: 0.2034 - accuracy: 0.9257 - val_loss: 0.1167 - val_accuracy: 0.9471\n",
      "Epoch 2/150\n",
      "8/8 [==============================] - 729s 91s/step - loss: 0.0820 - accuracy: 0.9634 - val_loss: 0.1096 - val_accuracy: 0.9471\n",
      "Epoch 3/150\n",
      "8/8 [==============================] - 730s 91s/step - loss: 0.0785 - accuracy: 0.9640 - val_loss: 0.1301 - val_accuracy: 0.9471\n",
      "Epoch 4/150\n",
      "8/8 [==============================] - 718s 90s/step - loss: 0.0843 - accuracy: 0.9634 - val_loss: 0.1060 - val_accuracy: 0.9472\n",
      "Epoch 5/150\n",
      "8/8 [==============================] - 722s 91s/step - loss: 0.0695 - accuracy: 0.9658 - val_loss: 0.0969 - val_accuracy: 0.9494\n",
      "Epoch 6/150\n",
      "8/8 [==============================] - 725s 91s/step - loss: 0.0573 - accuracy: 0.9741 - val_loss: 0.0872 - val_accuracy: 0.9608\n",
      "Epoch 7/150\n",
      "1/8 [==>...........................] - ETA: 10:22 - loss: 0.0491 - accuracy: 0.9795"
     ]
    }
   ],
   "source": [
    "unet = unet_model((IMG_WIDTH_HEIGHT, IMG_WIDTH_HEIGHT, IMG_CHANNELS), n_classes=3)\n",
    "\n",
    "unet.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "earlystopper = EarlyStopping(patience=patience, verbose=1)\n",
    "model_history = unet.fit(X_train, Y_train, validation_split=0.1, batch_size=batch_size, epochs=EPOCHS, callbacks=[earlystopper])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = unet.predict(X_train)\n",
    "test_predictions = unet.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import try_all_threshold\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.filters import threshold_otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(train_predictions)):\n",
    "\n",
    "    # making subplots\n",
    "    fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "    # set data with subplots and plot  \n",
    "    ax[0].imshow(X_train[i])\n",
    "    ax[0].set_title('Original')\n",
    "    \n",
    "    ax[1].imshow(Y_train[i], cmap='gray')\n",
    "    ax[1].set_title('Gold Mask')\n",
    "    \n",
    "    grays = rgb2gray(train_predictions[i])\n",
    "    thresh = threshold_otsu( grays )    \n",
    "    binary = grays > thresh\n",
    "\n",
    "    ax[2].imshow(binary, cmap='gray')\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(len(test_predictions)):\n",
    "\n",
    "    # making subplots\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "\n",
    "    # set data with subplots and plot  \n",
    "    ax[0].imshow(X_test[i])\n",
    "    ax[0].set_title('Original')\n",
    "    \n",
    "    grays = rgb2gray(test_predictions[i])\n",
    "    thresh = threshold_otsu( grays )    \n",
    "    binary = grays > thresh\n",
    "\n",
    "    ax[1].imshow(binary, cmap='gray')\n",
    "    ax[1].set_title('Predicted Mask')\n",
    "\n",
    "    fig.tight_layout()\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_model:\n",
    "    nome_saida = f'models/model-k={k}.h5'\n",
    "    #nome_saida = caminho_modelo+nome+'.h5'\n",
    "    unet.save(nome_saida)\n",
    "    print('Salvo como: ',nome_saida)\n",
    "print('Tempo de execução: ', time.time() - inicio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas = ['Original file name', 'area_em_pixels', 'altura_em_pixels', 'largura_em_pixels','IOU']\n",
    "data = []\n",
    "\n",
    "DATADIR1 = pathlib.Path(DATADIR1)\n",
    "DATADIR1_files = os.listdir(DATADIR1)\n",
    "\n",
    "DATADIR2 = pathlib.Path(DATADIR2)\n",
    "DATADIR2_files = os.listdir(DATADIR2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_predictions)):\n",
    "    \n",
    "    grays = rgb2gray(train_predictions[i])\n",
    "    thresh = threshold_otsu( grays )    \n",
    "    binary = grays > thresh\n",
    "\n",
    "\n",
    "    data.append(ut.take_area(X_test[i], DATADIR1_files[i]) + [ut.IOU(Y_train[i], binary)] )\n",
    "\n",
    "df = pd.DataFrame(data=data, columns =colunas)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTDIR = pathlib.Path(TESTDIR)\n",
    "TESTDIR_files = os.listdir(TESTDIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "039eedbdc3eafb3ff56e892b04b49d9f6f15fe71eac5c31af6e138083d479011"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
